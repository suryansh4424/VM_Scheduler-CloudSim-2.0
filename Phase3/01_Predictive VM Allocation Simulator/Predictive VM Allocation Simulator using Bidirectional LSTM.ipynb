{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47744ab6",
   "metadata": {},
   "source": [
    "# BiDirectional_LSTM Model for CPU Usage Prediction with VM Allocation Simulation -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34435268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ratho\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - loss: 0.0097\n",
      "Epoch 2/10\n",
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - loss: 0.0093\n",
      "Epoch 3/10\n",
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0092\n",
      "Epoch 4/10\n",
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - loss: 0.0093\n",
      "Epoch 5/10\n",
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0091\n",
      "Epoch 6/10\n",
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - loss: 0.0091\n",
      "Epoch 7/10\n",
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - loss: 0.0091\n",
      "Epoch 8/10\n",
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - loss: 0.0089\n",
      "Epoch 9/10\n",
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 0.0091\n",
      "Epoch 10/10\n",
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - loss: 0.0091\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "Bidirectional LSTM - MSE: 47.42624318691693, RMSE: 6.886671415634474, R²: 0.6183178114284122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Cumulative CPU usage: 17.566272735595703%\n",
      "CPU usage predicted to be 17.566272735595703%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Cumulative CPU usage: 35.4718074798584%\n",
      "CPU usage predicted to be 17.905534744262695%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Cumulative CPU usage: 53.768524169921875%\n",
      "CPU usage predicted to be 18.296716690063477%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Cumulative CPU usage: 72.18619728088379%\n",
      "CPU usage predicted to be 18.417673110961914%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Cumulative CPU usage: 90.8581485748291%\n",
      "Allocating 3 VMs due to cumulative CPU usage 90.8581485748291%\n",
      "VM0 VM_for_18.671951293945312 starts at 0\n",
      "VM1 VM_for_18.671951293945312 starts at 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Cumulative CPU usage: 18.572965621948242%\n",
      "CPU usage predicted to be 18.572965621948242%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Cumulative CPU usage: 37.42098808288574%\n",
      "CPU usage predicted to be 18.8480224609375%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Cumulative CPU usage: 56.122249603271484%\n",
      "CPU usage predicted to be 18.701261520385742%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Cumulative CPU usage: 74.86592483520508%\n",
      "CPU usage predicted to be 18.743675231933594%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Cumulative CPU usage: 93.66527938842773%\n",
      "Allocating 3 VMs due to cumulative CPU usage 93.66527938842773%\n",
      "VM2 VM_for_18.799354553222656 starts at 0\n",
      "VM3 VM_for_18.799354553222656 starts at 0\n",
      "VM_for_17.566272735595703 starts at 0\n",
      "VM_for_17.905534744262695 starts at 0\n",
      "VM_for_18.296716690063477 starts at 0\n",
      "VM_for_18.417673110961914 starts at 0\n",
      "VM_for_18.671951293945312 starts at 0\n",
      "VM_for_18.572965621948242 starts at 0\n",
      "VM_for_18.8480224609375 starts at 0\n",
      "VM_for_18.701261520385742 starts at 0\n",
      "VM_for_18.743675231933594 starts at 0\n",
      "VM_for_18.799354553222656 starts at 0\n",
      "VM_for_17.566272735595703 finishes at 10\n",
      "VM_for_17.905534744262695 finishes at 10\n",
      "VM_for_18.296716690063477 finishes at 10\n",
      "VM_for_18.417673110961914 finishes at 10\n",
      "VM_for_18.671951293945312 finishes at 10\n",
      "VM_for_18.572965621948242 finishes at 10\n",
      "VM_for_18.8480224609375 finishes at 10\n",
      "VM_for_18.701261520385742 finishes at 10\n",
      "VM_for_18.743675231933594 finishes at 10\n",
      "VM_for_18.799354553222656 finishes at 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import simpy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/ratho/OneDrive/Desktop/dataset1.txt'\n",
    "data = pd.read_csv(file_path, header=None)\n",
    "cpu_usage = data.values.flatten()\n",
    "\n",
    "# Define parameters\n",
    "sequence_length = 10\n",
    "\n",
    "# Prepare the data for the Bi-LSTM model (previous n values predict next value)\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        targets.append(data[i + seq_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "X, y = create_sequences(cpu_usage, sequence_length)\n",
    "\n",
    "# Scale the data\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, train_size=0.8, shuffle=False)\n",
    "\n",
    "# Reshape data for LSTM [samples, time steps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build and train Bidirectional LSTM model\n",
    "model_bi_lstm = Sequential()\n",
    "model_bi_lstm.add(Bidirectional(LSTM(units=50, return_sequences=True), input_shape=(X_train.shape[1], 1)))\n",
    "model_bi_lstm.add(Bidirectional(LSTM(units=50)))\n",
    "model_bi_lstm.add(Dense(1))\n",
    "model_bi_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_bi_lstm.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Predict using the Bi-LSTM model\n",
    "bi_lstm_predictions = model_bi_lstm.predict(X_test)\n",
    "bi_lstm_predictions = scaler_y.inverse_transform(bi_lstm_predictions)\n",
    "y_test_inv_bi = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate metrics\n",
    "mse_bi_lstm = mean_squared_error(y_test_inv_bi, bi_lstm_predictions)\n",
    "rmse_bi_lstm = np.sqrt(mse_bi_lstm)\n",
    "r2_bi_lstm = r2_score(y_test_inv_bi, bi_lstm_predictions)\n",
    "\n",
    "print(f'Bidirectional LSTM - MSE: {mse_bi_lstm}, RMSE: {rmse_bi_lstm}, R²: {r2_bi_lstm}')\n",
    "\n",
    "# Function to predict CPU usage and return a range (20% range as an example)\n",
    "def predict_cpu_usage(last_n_values):\n",
    "    prediction = model_bi_lstm.predict(last_n_values.reshape(1, -1, 1))\n",
    "    prediction = scaler_y.inverse_transform(prediction.reshape(-1, 1))\n",
    "    predicted_range = (prediction - (0.2 * prediction), prediction + (0.2 * prediction))  # 20% range\n",
    "    return prediction[0][0], predicted_range\n",
    "\n",
    "# SimPy Datacenter Simulation\n",
    "class Datacenter:\n",
    "    def __init__(self, env, capacity=10):\n",
    "        self.env = env\n",
    "        self.server = simpy.Resource(env, capacity=capacity)\n",
    "\n",
    "    def process_vm_request(self, vm):\n",
    "        with self.server.request() as req:\n",
    "            yield req\n",
    "            print(f\"{vm} starts at {self.env.now}\")\n",
    "            yield self.env.timeout(10)  # Simulate VM processing time\n",
    "            print(f\"{vm} finishes at {self.env.now}\")\n",
    "\n",
    "class VMAllocator:\n",
    "    def __init__(self, env, threshold=80):\n",
    "        self.env = env\n",
    "        self.threshold = threshold\n",
    "        self.cumulative_cpu_usage = 0  # Track the cumulative CPU usage\n",
    "        self.vm_counter = 0  # Counter to assign unique VM numbers\n",
    "\n",
    "    def allocate_vms(self, predicted_value, predicted_range):\n",
    "        self.cumulative_cpu_usage += predicted_value  # Add the predicted value to cumulative usage\n",
    "        print(f\"Cumulative CPU usage: {self.cumulative_cpu_usage}%\")\n",
    "\n",
    "        # Check if cumulative CPU usage exceeds the threshold\n",
    "        if self.cumulative_cpu_usage > self.threshold:\n",
    "            # If predicted CPU usage is high, prepare more VMs\n",
    "            num_vms = int((self.cumulative_cpu_usage - self.threshold) // 10) + 1\n",
    "            print(f\"Allocating {num_vms + 1} VMs due to cumulative CPU usage {self.cumulative_cpu_usage}%\")\n",
    "            for i in range(num_vms):\n",
    "                print(f\"VM{self.vm_counter} VM_for_{predicted_value} starts at 0\")\n",
    "                self.vm_counter += 1\n",
    "            self.cumulative_cpu_usage = 0  # Reset cumulative CPU usage after allocation\n",
    "        else:\n",
    "            print(f\"CPU usage predicted to be {predicted_value}%. No additional VMs needed.\")\n",
    "\n",
    "# Create SimPy environment\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Create Datacenter\n",
    "datacenter = Datacenter(env)\n",
    "\n",
    "# Create VM Allocator\n",
    "vm_allocator = VMAllocator(env)\n",
    "\n",
    "# Predict the next 10 values and allocate VMs based on the predicted CPU usage\n",
    "last_n_values = X_scaled[-1]  # Get the last sequence from the dataset\n",
    "predicted_values = []\n",
    "\n",
    "for _ in range(10):\n",
    "    predicted_value, predicted_range = predict_cpu_usage(last_n_values)\n",
    "    predicted_values.append((predicted_value, predicted_range))\n",
    "    \n",
    "    # Update the last_n_values to include the latest predicted value\n",
    "    last_n_values = np.append(last_n_values[1:], predicted_value / 100)  # Scale back to 0-1 range for the next prediction\n",
    "\n",
    "    # Allocate VMs based on the predicted value\n",
    "    vm_allocator.allocate_vms(predicted_value, predicted_range)\n",
    "\n",
    "# Simulate VM processing based on predicted values\n",
    "for predicted_value, predicted_range in predicted_values:\n",
    "    vm = f\"VM_for_{predicted_value}\"  # Create VM name based on predicted value\n",
    "    env.process(datacenter.process_vm_request(vm))\n",
    "\n",
    "# Run the simulation\n",
    "env.run(until=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4e5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
