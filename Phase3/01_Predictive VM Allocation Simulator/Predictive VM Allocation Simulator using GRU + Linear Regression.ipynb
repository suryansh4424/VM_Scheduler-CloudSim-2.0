{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3688f29b",
   "metadata": {},
   "source": [
    "# GRU + Linear Regression Model for CPU Usage Prediction with VM Allocation Simulation -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35af627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Linear Regression Model - MSE: 47.53494251113171, RMSE: 6.8945589062050745, R²: 0.6174430089314268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Cumulative CPU usage: 17.557531595230103%\n",
      "CPU usage predicted to be 17.557531595230103%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Cumulative CPU usage: 35.48869788646698%\n",
      "CPU usage predicted to be 17.931166291236877%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Cumulative CPU usage: 53.82277071475983%\n",
      "CPU usage predicted to be 18.334072828292847%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Cumulative CPU usage: 72.2984790802002%\n",
      "CPU usage predicted to be 18.47570836544037%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Cumulative CPU usage: 90.97769260406494%\n",
      "Allocating 2 VMs due to cumulative CPU usage 90.97769260406494%\n",
      "VM0 VM_for_18.679213523864746 starts at 0\n",
      "VM1 VM_for_18.679213523864746 starts at 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Cumulative CPU usage: 18.582463264465332%\n",
      "CPU usage predicted to be 18.582463264465332%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Cumulative CPU usage: 37.512823939323425%\n",
      "CPU usage predicted to be 18.930360674858093%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Cumulative CPU usage: 56.25198483467102%\n",
      "CPU usage predicted to be 18.739160895347595%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Cumulative CPU usage: 75.04400610923767%\n",
      "CPU usage predicted to be 18.79202127456665%. No additional VMs needed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Cumulative CPU usage: 93.91067624092102%\n",
      "Allocating 2 VMs due to cumulative CPU usage 93.91067624092102%\n",
      "VM2 VM_for_18.86667013168335 starts at 0\n",
      "VM3 VM_for_18.86667013168335 starts at 0\n",
      "VM_for_17.557531595230103 starts at 0\n",
      "VM_for_17.931166291236877 starts at 0\n",
      "VM_for_18.334072828292847 starts at 0\n",
      "VM_for_18.47570836544037 starts at 0\n",
      "VM_for_18.679213523864746 starts at 0\n",
      "VM_for_18.582463264465332 starts at 0\n",
      "VM_for_18.930360674858093 starts at 0\n",
      "VM_for_18.739160895347595 starts at 0\n",
      "VM_for_18.79202127456665 starts at 0\n",
      "VM_for_18.86667013168335 starts at 0\n",
      "VM_for_17.557531595230103 finishes at 10\n",
      "VM_for_17.931166291236877 finishes at 10\n",
      "VM_for_18.334072828292847 finishes at 10\n",
      "VM_for_18.47570836544037 finishes at 10\n",
      "VM_for_18.679213523864746 finishes at 10\n",
      "VM_for_18.582463264465332 finishes at 10\n",
      "VM_for_18.930360674858093 finishes at 10\n",
      "VM_for_18.739160895347595 finishes at 10\n",
      "VM_for_18.79202127456665 finishes at 10\n",
      "VM_for_18.86667013168335 finishes at 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense, Input\n",
    "import simpy\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/ratho/OneDrive/Desktop/dataset1.txt'\n",
    "data = pd.read_csv(file_path, header=None)\n",
    "cpu_usage = data.values.flatten()\n",
    "\n",
    "# Define parameters\n",
    "sequence_length = 10\n",
    "\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        targets.append(data[i + seq_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "X, y = create_sequences(cpu_usage, sequence_length)\n",
    "\n",
    "# Flatten X for Linear Regression\n",
    "X_flattened = X.reshape(-1, sequence_length)\n",
    "y_flattened = y\n",
    "\n",
    "# Scale the data\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X_flattened)\n",
    "y_scaled = scaler_y.fit_transform(y_flattened.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, train_size=0.8, shuffle=False)\n",
    "\n",
    "# Define and train the GRU model\n",
    "gru_model = Sequential()\n",
    "gru_model.add(Input(shape=(sequence_length, 1)))  # Input layer\n",
    "gru_model.add(GRU(50, activation='relu'))\n",
    "gru_model.add(Dense(1))\n",
    "\n",
    "gru_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Reshape data for GRU input\n",
    "X_train_gru = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_gru = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Train the GRU model with reduced epochs for faster training\n",
    "gru_model.fit(X_train_gru, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "# Predict using GRU\n",
    "gru_predictions = gru_model.predict(X_test_gru)\n",
    "\n",
    "# Apply Linear Regression to the GRU predictions\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(gru_predictions, y_test)\n",
    "\n",
    "# Predict with Linear Regression on GRU predictions\n",
    "lr_predictions = model_lr.predict(gru_predictions)\n",
    "\n",
    "# Rescale predictions\n",
    "lr_predictions_inv = scaler_y.inverse_transform(lr_predictions.reshape(-1, 1))\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lr = mean_squared_error(y_test_inv, lr_predictions_inv)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "r2_lr = r2_score(y_test_inv, lr_predictions_inv)\n",
    "\n",
    "print(f'Linear Regression Model - MSE: {mse_lr}, RMSE: {rmse_lr}, R²: {r2_lr}')\n",
    "\n",
    "# Function to predict CPU usage and return a range (20% range as an example)\n",
    "def predict_cpu_usage(last_n_values):\n",
    "    # Predict using GRU\n",
    "    gru_input = np.array(last_n_values).reshape(1, sequence_length, 1)\n",
    "    gru_pred = gru_model.predict(gru_input)\n",
    "    \n",
    "    # Adjust prediction with Linear Regression\n",
    "    lr_pred = model_lr.predict(gru_pred)\n",
    "    \n",
    "    # Predict range with 20% variation\n",
    "    predicted_range = (lr_pred - (0.2 * lr_pred), lr_pred + (0.2 * lr_pred))  # 20% range\n",
    "    return lr_pred[0] * 100, predicted_range  # Multiply by 100 to scale the result\n",
    "\n",
    "# SimPy Datacenter Simulation\n",
    "\n",
    "class Datacenter:\n",
    "    def __init__(self, env, capacity=10):\n",
    "        self.env = env\n",
    "        self.server = simpy.Resource(env, capacity=capacity)\n",
    "\n",
    "    def process_vm_request(self, vm):\n",
    "        with self.server.request() as req:\n",
    "            yield req\n",
    "            print(f\"{vm} starts at {self.env.now}\")\n",
    "            yield self.env.timeout(10)  # Simulate VM processing time\n",
    "            print(f\"{vm} finishes at {self.env.now}\")\n",
    "\n",
    "class VMAllocator:\n",
    "    def __init__(self, env, threshold=80):\n",
    "        self.env = env\n",
    "        self.threshold = threshold\n",
    "        self.cumulative_cpu_usage = 0  # Track the cumulative CPU usage\n",
    "        self.vm_counter = 0  # Counter to assign unique VM numbers\n",
    "\n",
    "    def allocate_vms(self, predicted_value, predicted_range):\n",
    "        self.cumulative_cpu_usage += predicted_value  # Add the predicted value to cumulative usage\n",
    "        print(f\"Cumulative CPU usage: {self.cumulative_cpu_usage}%\")\n",
    "\n",
    "        # Check if cumulative CPU usage exceeds the threshold\n",
    "        if self.cumulative_cpu_usage > self.threshold:\n",
    "            # If predicted CPU usage is high, prepare more VMs\n",
    "            num_vms = int((self.cumulative_cpu_usage - self.threshold) // 10) + 1\n",
    "            print(f\"Allocating {num_vms} VMs due to cumulative CPU usage {self.cumulative_cpu_usage}%\")\n",
    "            for i in range(num_vms):\n",
    "                print(f\"VM{self.vm_counter} VM_for_{predicted_value} starts at 0\")\n",
    "                self.vm_counter += 1\n",
    "            self.cumulative_cpu_usage = 0  # Reset cumulative CPU usage after allocation\n",
    "        else:\n",
    "            print(f\"CPU usage predicted to be {predicted_value}%. No additional VMs needed.\")\n",
    "\n",
    "# Create SimPy environment\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Create Datacenter\n",
    "datacenter = Datacenter(env)\n",
    "\n",
    "# Create VM Allocator\n",
    "vm_allocator = VMAllocator(env)\n",
    "\n",
    "# Predict the next 10 values and allocate VMs based on the predicted CPU usage\n",
    "last_n_values = X_scaled[-1]  # Get the last sequence from the dataset\n",
    "predicted_values = []\n",
    "\n",
    "for _ in range(10):\n",
    "    predicted_value, predicted_range = predict_cpu_usage(last_n_values)\n",
    "    predicted_values.append((predicted_value, predicted_range))\n",
    "    \n",
    "    # Update the last_n_values to include the latest predicted value\n",
    "    last_n_values = np.append(last_n_values[1:], predicted_value / 100)  # Scale back to 0-1 range for the next prediction\n",
    "\n",
    "    # Allocate VMs based on the predicted value\n",
    "    vm_allocator.allocate_vms(predicted_value, predicted_range)\n",
    "\n",
    "# Simulate VM processing based on predicted values\n",
    "for predicted_value, predicted_range in predicted_values:\n",
    "    vm = f\"VM_for_{predicted_value}\"  # Create VM name based on predicted value\n",
    "    env.process(datacenter.process_vm_request(vm))\n",
    "\n",
    "# Run the simulation\n",
    "env.run(until=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
